<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VoiceAI Transcriber</title>
    <script src="https://unpkg.com/@xenova/transformers@2.6.1"></script>
    <style>
        :root {
            --primary-color: #6C5CE7;
            --secondary-color: #00CEC9;
            --background-color: #F0F3F8;
            --text-color: #2D3436;
            --card-background: #FFFFFF;
            --accent-color: #FD79A8;
        }

        @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap');

        body {
            font-family: 'Poppins', sans-serif;
            margin: 0;
            padding: 0;
            background-color: var(--background-color);
            color: var(--text-color);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 20px;
            flex-grow: 1;
            display: flex;
            flex-direction: column;
        }

        header {
            text-align: center;
            margin-bottom: 40px;
        }

        h1 {
            color: var(--primary-color);
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .app-description {
            color: var(--text-color);
            opacity: 0.7;
            max-width: 600px;
            margin: 0 auto;
        }

        .app-layout {
            display: flex;
            flex-wrap: wrap;
            gap: 30px;
            justify-content: center;
        }

        .transcription-section, .llm-section {
            flex: 1;
            min-width: 300px;
            max-width: 500px;
        }

        .card {
            background-color: var(--card-background);
            border-radius: 15px;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
            padding: 30px;
            margin-bottom: 30px;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.15);
        }

        .button-group {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
        }

        button {
            background-color: var(--primary-color);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
            font-size: 1em;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        button:hover {
            background-color: #5A4ECD;
            transform: translateY(-2px);
        }

        button:disabled {
            background-color: #BDC3C7;
            cursor: not-allowed;
            transform: none;
        }

        button svg {
            margin-right: 8px;
        }

        #visualizer {
            width: 100%;
            height: 120px;
            background-color: var(--background-color);
            border-radius: 10px;
            margin-bottom: 20px;
        }

        #status {
            margin-top: 15px;
            font-weight: 500;
            color: var(--accent-color);
        }

        .content-area {
            background-color: var(--background-color);
            border: 2px solid var(--primary-color);
            border-radius: 10px;
            padding: 15px;
            min-height: 200px;
            max-height: 300px;
            overflow-y: auto;
            font-size: 0.9em;
            line-height: 1.6;
            font-family: inherit;  
            width: 100%;
            box-sizing: border-box;
            resize: vertical;
        }
        textarea.content-area {
            appearance: none;
            -webkit-appearance: none;
            -moz-appearance: none;
        }

        textarea.content-area:focus {
            outline: none;
            border-color: var(--secondary-color);
        }

        #llmResponse {
            resize: vertical;
        }

        .section-title {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
            color: var(--primary-color);
        }

        .section-title svg {
            margin-right: 10px;
        }
        .disclaimer-container {
            margin-top: 20px;
            text-align: center;
        }

        .disclaimer-toggle {
            color: var(--primary-color);
            text-decoration: underline;
            cursor: pointer;
        }

        .disclaimer-content {
            display: none;
            background-color: var(--card-background);
            border: 1px solid var(--primary-color);
            border-radius: 10px;
            padding: 20px;
            margin-top: 10px;
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
        }

        .disclaimer-content h1 {
            font-size: 1.5em;
            margin-bottom: 15px;
        }

        .disclaimer-content p, .disclaimer-content ol {
            font-size: 0.9em;
            line-height: 1.6;
        }

        footer {
            text-align: center;
            padding: 20px;
            background-color: var(--primary-color);
            color: white;
            margin-top: auto;
        }

        @media (max-width: 768px) {
            .app-layout {
                flex-direction: column;
            }

            .card {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Ai Medical Scribe</h1>
            <p class="app-description">Transcribe speech into medical note - all in your browser!</p>
        </header>
        <div class="app-layout">
            <div class="transcription-section">
                <div class="card">
                    <div class="button-group">
                        <button id="startRecord" disabled>
                            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                                <path d="M12 15C13.66 15 15 13.66 15 12V6C15 4.34 13.66 3 12 3C10.34 3 9 4.34 9 6V12C9 13.66 10.34 15 12 15Z" fill="currentColor"/>
                                <path d="M17 12C17 14.76 14.76 17 12 17C9.24 17 7 14.76 7 12H5C5 15.53 7.61 18.43 11 18.93V21H13V18.93C16.39 18.43 19 15.53 19 12H17Z" fill="currentColor"/>
                            </svg>
                            Start Recording
                        </button>
                        <button id="stopRecord" disabled>
                            <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                                <path d="M6 6H18V18H6V6Z" fill="currentColor"/>
                            </svg>
                            Stop Recording
                        </button>
                    </div>
                    <canvas id="visualizer"></canvas>
                    <div id="status">Ready to record...</div>
                </div>
                <div class="card">
                    <h2 class="section-title">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                            <path d="M20 2H4C2.9 2 2 2.9 2 4V22L6 18H20C21.1 18 22 17.1 22 16V4C22 2.9 21.1 2 20 2ZM20 16H5.17L4 17.17V4H20V16Z" fill="currentColor"/>
                            <path d="M12 15L14.59 12.41L16 13.82L16.59 13.23L14 10.64L12 8.64L8 12.64L9.41 14.05L12 11.46V15Z" fill="currentColor"/>
                        </svg>
                        Transcription
                    </h2>
                    <textarea id="transcription" class="content-area"></textarea>
                </div>
            </div>
            <div class="llm-section">
                <div class="card">
                    <h2 class="section-title">
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                            <path d="M21 11.5C21 16.75 16.75 21 11.5 21C6.25 21 2 16.75 2 11.5C2 6.25 6.25 2 11.5 2" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                            <path d="M22 22L20 20" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                            <path d="M15 8C14.0054 8 13.0516 8.39588 12.3483 9.10041C11.6451 9.80494 11.25 10.7613 11.25 11.7586C11.25 12.7559 11.6451 13.7123 12.3483 14.4168C13.0516 15.1213 14.0054 15.5172 15 15.5172C15.9946 15.5172 16.9484 15.1213 17.6517 14.4168C18.3549 13.7123 18.75 12.7559 18.75 11.7586C18.75 10.7613 18.3549 9.80494 17.6517 9.10041C16.9484 8.39588 15.9946 8 15 8Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                        </svg>
                        Medical Note
                    </h2>
                    <button id="sendToLLM" disabled>
                        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                            <path d="M2.01 21L23 12L2.01 3L2 10L17 12L2 14L2.01 21Z" fill="currentColor"/>
                        </svg>
                        Create Medical Note
                    </button>
                    <textarea id="llmResponse" class="content-area" readonly></textarea>
                </div>
            </div>
        </div>
        <div class="disclaimer-container">
        <span class="disclaimer-toggle">Read terms of use before proceeding. Click here to read.</span>
        <div class="disclaimer-content">
            <h1>Disclaimer: AI-Assisted Medical Note Creator</h1>
            <p>This AI-assisted medical note creation tool is designed to support healthcare professionals in documenting patient encounters. Please read and understand the following important information:</p>
            <ol>
                <li><strong>Intended Use</strong>: This tool is intended for use by licensed healthcare professionals only. It is designed to assist in the creation of medical notes, not to replace professional medical judgment or decision-making.</li>
                <li><strong>AI Limitations</strong>: The AI system used in this tool is based on machine learning algorithms and may not always produce accurate or complete information. It is not capable of independent medical reasoning or diagnosis. AI hallucinate or generate wrong information or omit information.</li>
                <li><strong>User Responsibility</strong>: The healthcare professional using this tool is solely responsible for the content, accuracy, and completeness of all medical notes. All AI-generated content must be thoroughly reviewed, verified, and edited as necessary before being incorporated into official medical records.</li>
                <li><strong>Not a Diagnostic Tool</strong>: This AI system is not designed to make medical diagnoses or treatment recommendations. Any such information that may be generated should be considered as suggestions only and must be independently verified by the healthcare professional.</li>
                <li><strong>Privacy and Security</strong>: While this site is able to run locally in the bowser once the models are downloaded, users are responsible for ensuring compliance with all applicable privacy laws and regulations, including HIPAA (Health Insurance Portability and Accountability Act) in the United States and other applicable laws and regulation in all regions where this is used. Make sure this tool can be used in your region and in your institution before using this tool.</li>
                <li><strong>No Substitute for Professional Judgment</strong>: This tool should never be used as a substitute for professional medical judgment. Healthcare professionals should rely on their training, experience, and direct patient evaluation when making clinical decisions.</li>
                <li><strong>Continuous Learning</strong>: The AI model may be updated periodically. Users should stay informed about any changes or improvements to the system and adjust their usage accordingly.</li>
                <li><strong>Errors and Omissions</strong>: Neither the developers of this tool nor the model creators are liable for any errors, omissions, or consequences arising from the use of this tool.</li>
                <li><strong>Training and Familiarization</strong>: Healthcare professionals should undergo appropriate training and familiarization with this tool before using it in clinical practice.</li>
            </ol>
            <p>By using this AI-assisted medical note creation tool, you acknowledge that you have read, understood, and agree to the terms outlined in this disclaimer. Remember, the ultimate responsibility for patient care and documentation lies with the healthcare professional.</p>
            <p>Whisper model license: <a href="https://github.com/openai/whisper/blob/main/LICENSE" target="_blank">https://github.com/openai/whisper/blob/main/LICENSE</a></p>
            <p>To learn more about Chrome Built-in AI visit - <a href="https://developer.chrome.com/docs/ai/built-in" target="_blank">https://developer.chrome.com/docs/ai/built-in</a></p>
        </div>
    </div>
    </div>
    <footer>
        <p>GitHub Repo: <a href="https://github.com/johnyquest7/whisper_chrome_ai">https://github.com/johnyquest7/whisper_chrome_ai</a></p> 
    </footer>

<script type="module">
    import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.6.1';

    env.allowLocalModels = false;
    env.remoteModels = {
        'Xenova/whisper-tiny': 'https://huggingface.co/Xenova/whisper-tiny/resolve/main/'
    };

    let mediaRecorder;
    let audioChunks = [];
    let transcriber;
    let audioContext;
    let analyser;
    let visualizer;
    let visualizerContext;

    const startRecord = document.getElementById('startRecord');
    const stopRecord = document.getElementById('stopRecord');
    const status = document.getElementById('status');
    const transcription = document.getElementById('transcription');
    const sendToLLM = document.getElementById('sendToLLM');
    const llmResponse = document.getElementById('llmResponse');
    visualizer = document.getElementById('visualizer');
    visualizerContext = visualizer.getContext('2d');

    (async function loadModel() {
        try {
            status.textContent = 'Loading model...';
            transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny');
            status.textContent = 'Model loaded. Ready to record.';
            startRecord.disabled = false;
        } catch (error) {
            console.error('Error loading model:', error);
            status.textContent = 'Error: Unable to load the model.';
        }
    })();

    startRecord.addEventListener('click', async () => {
        try {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            analyser = audioContext.createAnalyser();
            const source = audioContext.createMediaStreamSource(stream);
            source.connect(analyser);

            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
            mediaRecorder.start();

            status.textContent = 'Recording... (speak for at least 5 seconds)';
            startRecord.disabled = true;
            stopRecord.disabled = false;
            sendToLLM.disabled = true;

            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };

            visualize();
        } catch (error) {
            console.error('Error starting recording:', error);
            status.textContent = 'Error: Unable to access microphone';
        }
    });

    stopRecord.addEventListener('click', () => {
        if (mediaRecorder && mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
            status.textContent = 'Processing...';
            startRecord.disabled = false;
            stopRecord.disabled = true;

            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                audioChunks = [];
                await transcribeAudio(audioBlob);
            };
        }
    });

    async function transcribeAudio(audioBlob) {
        try {
            const arrayBuffer = await audioBlob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            const offlineContext = new OfflineAudioContext(1, audioBuffer.duration * 16000, 16000);
            const source = offlineContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(offlineContext.destination);
            source.start();
            const resampled = await offlineContext.startRendering();

            const float32Array = resampled.getChannelData(0);

            const result = await transcriber(float32Array, {
                chunk_length_s: 30,
                stride_length_s: 5,
                language: 'english',
                task: 'transcribe',
                sampling_rate: 16000,
                return_timestamps: true
            });

            transcription.value = 'Transcription: ' + result.text;
            status.textContent = 'Transcription complete.';
            sendToLLM.disabled = false;
        } catch (error) {
            console.error('Transcription error:', error);
            status.textContent = 'Error during transcription.';
        }
    }

    function visualize() {
        const WIDTH = visualizer.width;
        const HEIGHT = visualizer.height;
        analyser.fftSize = 256;
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        visualizerContext.clearRect(0, 0, WIDTH, HEIGHT);

        function draw() {
            const drawVisual = requestAnimationFrame(draw);
            analyser.getByteFrequencyData(dataArray);
            visualizerContext.fillStyle = 'rgb(200, 200, 200)';
            visualizerContext.fillRect(0, 0, WIDTH, HEIGHT);
            const barWidth = (WIDTH / bufferLength) * 2.5;
            let barHeight;
            let x = 0;

            for(let i = 0; i < bufferLength; i++) {
                barHeight = dataArray[i] / 2;
                visualizerContext.fillStyle = 'rgb(' + (barHeight + 100) + ',50,50)';
                visualizerContext.fillRect(x, HEIGHT - barHeight / 2, barWidth, barHeight);
                x += barWidth + 1;
            }
        }

        draw();
    }
    sendToLLM.addEventListener('click', async () => {
        const transcriptionText = transcription.value.replace('Transcription: ', '');
        try {
            status.textContent = 'Checking LLM availability...';
            const { available } = await ai.assistant.capabilities();
            if (available === "no") {
                throw new Error('LLM is not available on this device.');
            }
            status.textContent = 'Creating LLM session...';
            let session;
            try {
                session = await ai.assistant.create({
                    temperature: 0.1,
                    topK: 3,
                    monitor(m) {
                        m.addEventListener("downloadprogress", e => {
                            const percentage = Math.round((e.loaded / e.total) * 100);
                            status.textContent = `Downloading LLM... ${percentage}%`;
                        });
                    }
                });
            } catch (error) {
                console.error('Error creating assistant session:', error);
                status.textContent = 'Error: Unable to create LLM session.';
                sendToLLM.disabled = false;
                return;
            }
            status.textContent = 'Sending to LLM...';
            sendToLLM.disabled = true;
            const prompt = `Convert the following medical transcript to a structured medical note. Transcript: "${transcriptionText}"`;
            llmResponse.value = ''; // Clear previous response
            try {
                let tempResponse = ''; // Temporary string to store response content
                const result = await session.prompt(prompt);
                llmResponse.value = result; // Once all chunks are received, update the final response value
                status.textContent = 'LLM response complete.';
            } catch (error) {
                console.error('Error during LLM interaction:', error);
                status.textContent = 'Error: Failed to get LLM response.';
                llmResponse.value = 'An error occurred while processing your request.';
            } finally {
                sendToLLM.disabled = false;
                if (session && typeof session.destroy === 'function') {
                    session.destroy();
                }
            }
        } catch (error) {
            console.error('Error interacting with LLM:', error);
            status.textContent = 'Error: LLM interaction is not available.';
            sendToLLM.disabled = false;
        }
        document.querySelector('.disclaimer-toggle').addEventListener('click', function() {
            const disclaimerContent = document.querySelector('.disclaimer-content');
            disclaimerContent.style.display = disclaimerContent.style.display === 'none' ? 'block' : 'none';
    });
       

</script>
</body>
</html>
